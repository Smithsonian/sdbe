
@inproceedings{weintroub14,
  title = {{SWARM}: A Compact High Resolution Correlator and Wideband {VLBI} Phased Array Upgrade for {SMA}},
  volume = {224},
  shorttitle = {{SWARM}},
  url = {http://adsabs.harvard.edu/abs/2014AAS...22441405W},
  abstract = {A new digital back end (DBE) is being commissioned on Mauna Kea. The 
``SMA Wideband Astronomical ROACH2 Machine'', or SWARM,
processes a 4 GHz usable band in single polarization mode and is
flexibly reconfigurable for 2 GHz full Stokes dual polarization. The
hardware is based on the open source Reconfigurable Open Architecture
Computing Hardware 2 (ROACH2) platform from the Collaboration for
Astronomy Signal Processing and Electronics Research (CASPER). A 5 GSps
quad-core analog-to-digital converter board uses a commercial chip from
e2v installed on a CASPER-standard printed circuit board designed by
Homin Jiang's group at ASIAA. Two ADC channels are provided per
ROACH2, each sampling a 2.3 GHz Nyquist band generated by a custom
wideband block downconverter (BDC). The ROACH2 logic includes
16k-channel Polyphase Filterbank (F-engine) per input followed by a 10
GbE switch based corner-turn which feeds into correlator-accumulator
logic (X-engines) co-located with the F-engines. This arrangement makes
very effective use of a small amount of digital hardware (just 8 ROACH2s
in 1U rack mount enclosures). The primary challenge now is to meet
timing at full speed for a large and very complex FPGA bit code. Design
of the VLBI phased sum and recorder interface logic is also in process.
Our poster will describe the instrument design, with the focus on the
particular challenges of ultra wideband signal processing. Early
connected commissioning and science verification data will be presented.},
  timestamp = {2015-08-03 13:26:21},
  urldate = {2015-08-03},
  author = {Weintroub, Jonathan},
  month = jun,
  year = {2014}
}

@book{oppenheim10,
  address = {Upper Saddle River {NJ}},
  edition = {3rd ed.},
  series = {Prentice-Hall signal processing series},
  title = {Discrete-time signal processing},
  lccn = {TK5102.9},
  abstract = {"The definitive, authoritative text on DSP - ideal for those with an introductory-level knowledge of signals and systems. Written by prominent DSP pioneers, it provides thorough treatment of the fundamental theorems and properties of discrete-time linear systems, filtering, sampling, and discrete-time Fourier Analysis. By focusing on the general and universal concepts in discrete-time signal processing, it remains vital and relevant to the new challenges arising in the field."--Publisher's description.},
  language = {eng},
  timestamp = {2015-07-08 12:49:52},
  publisher = {Prentice Hall},
  author = {Oppenheim, Alan V.},
  collaborator = {Schafer, Ronald W.},
  year = {2010},
  keywords = {DES (System analysis),Discrete event systems,Discrete-time systems.,Sampled-data systems,Signal processing Mathematics.}
}

@book{lyons11,
  address = {Upper Saddle River, {NJ}},
  edition = {3rd ed.},
  title = {Understanding digital signal processing},
  language = {eng},
  timestamp = {2015-07-08 14:01:13},
  publisher = {Prentice Hall},
  author = {Lyons, Richard G.},
  year = {2011},
  keywords = {Digital signal processing,Signal processing Digital techniques.}
}

@book{wang01,
  address = {Ottawa},
  title = {Digital sampling rate conversion principles and implementation},
  abstract = {The resampling of a signal involves the conversion from the initial sampling rate to a new and different one. This is often necessary in practical applications because the sampling rate is often fixed while the desired sampling rate may depend on the application or a signal parameter, such as the symbol rate or channel spacing. This problem often arises in software radio systems where the sampling rate is determined by hardware constraints. Although resampling algorithms have been developed and implemented in commercial software libraries, these algorithms often have undesirable limitations. This report describes a fairly general resampling algorithm useful in many practical signal processing applications. To obtain flexibility, it implements a periodically time varying filter structure in such a way that it keeps track of state variables and also makes provisions for input blocks of arbitrary length. The algorithm also achieves a relatively high processing throughput when implemented in software.},
  language = {Abstract and executive summary in English and French.},
  timestamp = {2015-07-08 12:49:42},
  publisher = {Defence Research Establishment Ottawa},
  author = {Wang, Sichun and Kozminchuk, Brian and {Defence Research Establishment Ottawa}},
  year = {2001}
}

@article{crochiere81,
  title = {Interpolation and decimation of digital signals \#8212;A tutorial review},
  volume = {69},
  issn = {0018-9219},
  doi = {10.1109/PROC.1981.11969},
  abstract = {The concepts of digital signal processing are playing an increasingly important role in the area of multirate signal processing, i.e. signal processing algorithms that involve more than one sampling rate. In this paper we present a tutorial overview of multirate digital signal processing as applied to systems for decimation and interpolation. We first discuss a theoretical model for such systems (based on the sampling theorem) and then show how various structures can be derived to provide efficient implementations of these systems. Design techniques for the linear-time-invariant components of these systems (the digital filter) are discussed, and finally the ideas behind multistage implementations for increased efficiency are presented.},
  timestamp = {2015-07-08 12:49:31},
  number = {3},
  journal = {Proceedings of the {IEEE}},
  author = {Crochiere, R.E. and Rabiner, L.},
  month = mar,
  year = {1981},
  keywords = {Digital signal processing,Interpolation,Nonuniform sampling,Sampling methods,Sequences,Signal processing,Signal processing algorithms,Signal sampling,Tutorial},
  pages = {300--331},
  file = {IEEE Xplore Abstract Record:/home/krosenfe/.mozilla/firefox/5dl2iz3a.default/zotero/storage/SEZH7N3A/login.html:text/html}
}

@article{tao_sampling_2008,
  title = {Sampling and Sampling Rate Conversion of Band Limited Signals in the Fractional Fourier Transform Domain},
  volume = {56},
  issn = {1053-587X},
  doi = {10.1109/TSP.2007.901666},
  abstract = {The fractional Fourier transform (FRFT) has become a very active area in signal processing community in recent years, with many applications in radar, communication, information security, etc., This study carefully investigates the sampling of a continuous-time band limited signal to obtain its discrete-time version, as well as sampling rate conversion, for the FRFT. Firstly, based on product theorem for the FRFT, the sampling theorems and reconstruction formulas are derived, which explain how to sample a continuous-time signal to obtain its discrete-time version for band limited signals in the fractional Fourier domain. Secondly, the formulas and significance of decimation and interpolation are studied in the fractional Fourier domain. Using the results, the sampling rate conversion theory for the FRFT with a rational fraction as conversion factor is deduced, which illustrates how to sample the discrete-time version without aliasing. The theorems proposed in this study are the generalizations of the conventional versions for the Fourier transform. Finally, the theory introduced in this paper is validated by simulations.},
  timestamp = {2015-07-03 18:40:54},
  number = {1},
  journal = {{IEEE} Transactions on Signal Processing},
  author = {Tao, Ran and Deng, Bing and Zhang, Wei-Qiang and Wang, Yue},
  month = jan,
  year = {2008},
  keywords = {bandlimited signals,continuous-time band limited signal,discrete-time signal,Discrete transforms,Fourier transforms,fractional Fourier transform domain,Fractional Fourier transform (FRFT),FRFT,Information security,Interpolation,product theorem,Radar signal processing,reconstruction formulas,Sampling methods,sampling rate conversion,sampling theorem,Signal processing,Signal processing algorithms,signal reconstruction,Signal sampling,Time frequency analysis},
  pages = {158--171},
  file = {IEEE Xplore Abstract Record:/home/krosenfe/.mozilla/firefox/5dl2iz3a.default/zotero/storage/FBD6JW8M/login.html:text/html}
}

@article{bi11,
  title = {Sampling Rate Conversion in the Frequency Domain {[}{DSP} Tips and Tricks]},
  volume = {28},
  issn = {1053-5888},
  doi = {10.1109/MSP.2011.940413},
  abstract = {Sampling rate conversion (SRC) is usually performed in the time domain by using the operations of up-sampling, filtering, and down-sampling. However, it is also possible to perform the SRC in the frequency domain by formulating the desired spectrum from the spectrum of an input signal. This article shows how to perform SRC for both integer and fractional-rate conversion by manipulating the discrete Fourier transform (DFT), implemented using the fast Fourier transform (FFT), of a time-domain signal. The analysis on error performance and the required computational complexities show that by using the FFT, for both short and long input sequences, improvements in conversion accuracy is achieved at reduced computational costs.},
  timestamp = {2015-07-08 12:49:35},
  number = {3},
  journal = {{IEEE} Signal Processing Magazine},
  author = {Bi, Guoan and Mitra, S.K.},
  month = may,
  year = {2011},
  keywords = {computational complexity,conversion accuracy,Digital signal processing,discrete Fourier transform,discrete Fourier transforms,error performance,fast Fourier transform,fractional-rate conversion,frequency domain,frequency-domain analysis,Frequency domain analysis,integer,Interpolation,sampling rate conversion,Signal processing algorithms,Signal sampling,signal spectrum,Time domain analysis,time-domain signal},
  pages = {140--144},
  file = {IEEE Xplore Abstract Record:/home/krosenfe/.mozilla/firefox/5dl2iz3a.default/zotero/storage/Q5J5KHBS/login.html:text/html}
}

@book{gold69,
  series = {Lincoln Laboratory publications},
  title = {Digital processing of signals},
  lccn = {TK7872.F5},
  language = {eng},
  timestamp = {2015-07-08 12:50:01},
  publisher = {New York, {McGraw}-Hill 1969},
  author = {Gold, Bernard},
  collaborator = {Rader, Charles M. and Rader, Charles M.},
  year = {1969},
  keywords = {Digital electric filters,Electric filters, Digital.,Filters, Digital electric}
}

@article{yeh82,
  title = {A direct {FFT} scheme for interpolation, decimation and amplitude modulation.},
  timestamp = {2015-07-08 12:49:38},
  journal = {Proc. 16th Asilomar Conf. Circuits, Syst., Computers},
  author = {Yeh, M. and Melsa, J. and Cohn, D.},
  year = {1982},
  pages = {437--441}
}

@article{fraser89,
  title = {Interpolation by the {FFT} revisited-an experimental investigation},
  volume = {37},
  issn = {0096-3518},
  doi = {10.1109/29.17559},
  abstract = {A numerical investigation into the accuracy of interpolation by, fast Fourier transform (FFT), using a sinusoidal test signal, is described. The method is precisely defined, including a previously unnoticed detail which makes a significant difference to the accuracy of the result. The experiments show that, with no input windowing, the accuracy of interpolation is almost independent of sinusoidal wavelength very close to the Nyquist limit. The resulting RMS error is inversely proportional to input sequence length and is very low for sequence lengths likely to be encountered in practice. As wavelength passes through the Nyquist limit, there is a sudden increase in error, as is expected from sampling theory. If the sequence ends are windowed by short, cosine half-bells, accuracy is further improved at longer wavelengths. In comparison, small-kernal convolution methods, such as linear interpolation and cubic convolution, perform badly at wavelengths anywhere near the Nyquist limit},
  timestamp = {2015-07-08 12:49:26},
  number = {5},
  journal = {{IEEE} Transactions on Acoustics, Speech and Signal Processing},
  author = {Fraser, D.},
  month = may,
  year = {1989},
  keywords = {Concurrent computing,Convolution,Digital filters,Digital signal processing,discrete Fourier transforms,fast Fourier transform,fast Fourier transforms,FFT,Frequency,input sequence length,Interpolation,Nyquist limit,RMS error,Sampling methods,sampling theory,sinusoidal test signal,sinusoidal wavelength,Testing},
  pages = {665--675},
  file = {IEEE Xplore Abstract Record:/home/krosenfe/.mozilla/firefox/5dl2iz3a.default/zotero/storage/F2URZU3V/login.html:text/html}
}

@incollection{turkowski90,
  address = {San Diego, {CA}, {USA}},
  title = {Graphics Gems},
  url = {http://dl.acm.org/citation.cfm?id=90767.90805},
  timestamp = {2015-07-08 12:49:48},
  urldate = {2015-07-05},
  publisher = {Academic Press Professional, Inc.},
  author = {Turkowski, Ken},
  editor = {Glassner, Andrew S.},
  year = {1990},
  pages = {147--165}
}

@book{vaidyanathan93,
  title = {Multirate Systems And Filter Banks},
  isbn = {978-81-7758-942-9},
  language = {en},
  timestamp = {2015-07-08 12:49:45},
  publisher = {Dorling Kindersley},
  author = {Vaidyanathan, P. P.},
  year = {1993}
}

@inproceedings{vanderveldt12,
  address = {New York, {NY}, {USA}},
  series = {Astro-{HPC} '12},
  title = {A Polyphase Filter for {GPUs} and Multi-core Processors},
  isbn = {978-1-4503-1338-4},
  url = {http://doi.acm.org/10.1145/2286976.2286986},
  doi = {10.1145/2286976.2286986},
  abstract = {Software radio telescopes are a new development in radio astronomy. Rather than using expensive dishes, they form distributed sensor networks of tens of thousands of simple receivers. Signals are processed in software instead of custom-built hardware, taking advantage of the flexibility that software solutions offer. In turn, the data rates are high and the processing requirements challenging. GPUs and multi-core processors are promising devices to provide the required processing power. LOFAR1, the largest radio telescope, is a prime example of a software radio telescope. In this paper, we discuss an optimized implementation of the polyphase filter bank used by LOFAR. We compare the following architectures: Intel Core i7, NVIDIA GTX580, ATI HD5870, and MicroGrid{[}7]. We present a novel way to compute polyphase filters efficiently on GPUs, and also discuss hardware limitations and energy efficiency.},
  timestamp = {2015-08-03 13:08:17},
  urldate = {2015-07-12},
  booktitle = {Proceedings of the 2012 Workshop on High-Performance Computing for Astronomy Date},
  publisher = {{ACM}},
  author = {van der Veldt, Karel and van Nieuwpoort, Rob and Varbanescu, Ana Lucia and Jesshope, Chris},
  year = {2012},
  keywords = {CUDA,Digital signal processing,FIR filter,LOFAR,MicroGrid,OpenCL,polyphase filter,Radio Astronomy},
  pages = {33--40}
}

@article{harris_digital_2003,
  title = {Digital receivers and transmitters using polyphase filter banks for wireless communications},
  volume = {51},
  issn = {0018-9480},
  doi = {10.1109/TMTT.2003.809176},
  abstract = {Provides a tutorial overview of multichannel wireless digital receivers and the relationships between channel bandwidth, channel separation, and channel sample rate. The overview makes liberal use of figures to support the underlying mathematics. A multichannel digital receiver simultaneously down-converts a set of frequency-division-multiplexed (FDM) channels residing in a single sampled data signal stream. In a similar way, a multichannel digital transmitter simultaneously up-converts a number of baseband signals to assemble a set of FDM channels in a single sampled data signal stream. The polyphase filter bank has become the architecture of choice to efficiently accomplish these tasks. This architecture uses three interacting processes to assemble or to disassemble the channelized signal set. In a receiver, these processes are an input commutator to effect spectral folding or aliasing due to a reduction in sample rate, a polyphase M-path filter to time align the partitioned and resampled time series in each path, and a discrete Fourier transform to phase align and separate the multiple baseband aliases. In a transmitter, these same processes operate in a related manner to alias baseband signals to high order Nyquist zones while increasing the sample rate with the output commutator.},
  timestamp = {2015-07-12 18:50:38},
  number = {4},
  journal = {{IEEE} Transactions on Microwave Theory and Techniques},
  author = {Harris, F.J. and Dick, C. and Rice, M.},
  month = apr,
  year = {2003},
  keywords = {aliasing,Assembly,Bandwidth,Baseband,baseband signals,channel bandwidth,channel bank filters,channel sample rate,channel separation,digital radio,digital receivers,digital transmitters,discrete Fourier transform,discrete Fourier transforms,FDM,Filter bank,Frequency,frequency division multiplexing,high order Nyquist zones,input commutator,interacting processes,land mobile radio,Mathematics,multiple baseband aliases,polyphase filter banks,polyphase M-path filter,radio receivers,radio transmitters,Signal processing,single sampled data signal stream,spectral folding,time series,Transmitters,Wireless communication,wireless communications},
  pages = {1395--1412},
  file = {IEEE Xplore Abstract Record:/home/krosenfe/.mozilla/firefox/5dl2iz3a.default/zotero/storage/NM9PQRX3/login.html:text/html}
}

@inproceedings{kim14b,
  title = {Implementation of a low-complexity low-latency arbitrary resampler on {GPUs}},
  doi = {10.1109/DCAS.2014.6965333},
  abstract = {Modern communication systems have data rates and sampling rates that are tightly coupled. Resampling is necessary in order to convert to some desired sampling rate, which is usually a multiple of the data rate. The resampling process is an integral part of transceiver systems and must be designed accurately and carefully. In this paper, we present a low complexity and low latency arbitrary resampling method based on graphics processing units (GPUs). Our proposed flexible and all-software-based resampling method requires no precomputation of filters and yet yields high performance by taking advantage of unique features found in GPUs.},
  timestamp = {2015-08-03 13:12:24},
  booktitle = {Circuits and Systems Conference ({DCAS}), 2014 {IEEE} Dallas},
  author = {Kim, S.C. and Bhattacharyya, S.S.},
  month = oct,
  year = {2014},
  keywords = {all-software-based resampling method,Arbitrary resampling,arbitrary resampling method,Arrays,Clocks,DSP accelerator,GPU,GPU-based radio,GPU front-end receiver,graphics processing units,Indexes,Interpolation,low-complexity low-latency arbitrary resampler,Multiaccess communication,sample rate conversion,Sampling methods,Spread spectrum communication,system clock,timing},
  pages = {1--4},
  file = {IEEE Xplore Abstract Record:/home/krosenfe/.mozilla/firefox/5dl2iz3a.default/zotero/storage/82NE5GCX/articleDetails.html:text/html}
}

@article{deller07,
  title = {{DiFX}: A Software Correlator for Very Long Baseline Interferometry Using Multiprocessor Computing Environments},
  volume = {119},
  issn = {0004-6280},
  shorttitle = {{DiFX}},
  url = {http://adsabs.harvard.edu/abs/2007PASP..119..318D},
  doi = {10.1086/513572},
  abstract = {We describe the development of an FX-style correlator for very long 
baseline interferometry (VLBI), implemented in software and intended to
run in multiprocessor computing environments, such as large clusters of
commodity machines (Beowulf clusters) or computers specifically designed
for high-performance computing, such as multiprocessor shared-memory
machines. We outline the scientific and practical benefits for VLBI
correlation, these chiefly being due to the inherent flexibility of
software and the fact that the highly parallel and scalable nature of
the correlation task is well suited to a multiprocessor computing
environment. We suggest scientific applications where such an approach
to VLBI correlation is most suited and will give the best returns. We
report detailed results from the Distributed FX (DiFX) software
correlator running on the Swinburne supercomputer (a Beowulf cluster of
{\textasciitilde}300 commodity processors), including measures of the performance of the
system. For example, to correlate all Stokes products for a 10 antenna
array with an aggregate bandwidth of 64 MHz per station, and using
typical time and frequency resolution, currently requires an order of
100 desktop-class compute nodes. Due to the effect of Moore's law on
commodity computing performance, the total number and cost of compute
nodes required to meet a given correlation task continues to decrease
rapidly with time. We show detailed comparisons between DiFX and two
existing hardware-based correlators: the Australian Long Baseline Array
S2 correlator and the NRAO Very Long Baseline Array correlator. In both
cases, excellent agreement was found between the correlators. Finally,
we describe plans for the future operation of DiFX on the Swinburne
supercomputer for both astrophysical and geodetic science.},
  timestamp = {2015-08-03 13:00:37},
  urldate = {2015-07-15},
  journal = {Publications of the Astronomical Society of the Pacific},
  author = {Deller, A. T. and Tingay, S. J. and Bailes, M. and West, C.},
  month = mar,
  year = {2007},
  keywords = {instrumentation: interferometers,Radio Continuum: General,Radio Lines: General,Stars: Pulsars: General,techniques: interferometric},
  pages = {318--336}
}

@article{cooper70,
  title = {Correlators with two-bit quantization},
  volume = {23},
  issn = {0004-9506},
  url = {http://adsabs.harvard.edu/abs/1970AuJPh..23..521C},
  abstract = {Properties of correlators for partially coherent noise signals employing two-bit quantization of the input signals are considered.  Aspects discussed are the signal-to-noise ratio, the relationship between the two-bit and the continuous correlation coefficients, and the stability requirements for the quantizers.  Means of measuring the two-bit correlation coefficient with counter-type logic are considered, and simplifications giving a performance intermediate between two-bit and one-bit systems are investigated.},
  timestamp = {2015-08-03 13:34:57},
  urldate = {2015-07-15},
  journal = {Australian Journal of Physics},
  author = {Cooper, B. F. C.},
  month = aug,
  year = {1970},
  pages = {521--527}
}

@book{thompson01,
  title = {Interferometry and Synthesis in Radio Astronomy, 2nd Edition},
  url = {http://adsabs.harvard.edu/abs/2001isra.book.....T},
  abstract = {Not Available},
  timestamp = {2015-08-03 13:35:14},
  urldate = {2015-07-15},
  author = {Thompson, A. Richard and Moran, James M. and Swenson, George W., Jr.},
  year = {2001}
}

@misc{_cufft,
  type = {concept},
  title = {{cuFFT}},
  url = {http://docs.nvidia.com/cuda/cufft/index.html\#axzz3fyoT86V2},
  abstract = {The API reference guide for cuFFT, the CUDA Fast Fourier Transform library.},
  timestamp = {2015-07-15 17:03:30},
  urldate = {2015-07-15},
  file = {Snapshot:/home/krosenfe/.mozilla/firefox/5dl2iz3a.default/zotero/storage/UUHHQ6KB/index.html:text/html}
}

@article{cooley65,
  title = {An algorithm for the machine calculation of complex Fourier series},
  volume = {19},
  issn = {0025-5718, 1088-6842},
  url = {http://www.ams.org/mcom/1965-19-090/S0025-5718-1965-0178586-1/},
  doi = {10.1090/S0025-5718-1965-0178586-1},
  timestamp = {2015-08-03 13:13:26},
  number = {90},
  urldate = {2015-07-15},
  journal = {Mathematics of Computation},
  author = {Cooley, James W. and Tukey, John W.},
  year = {1965},
  pages = {297--301},
  file = {Full Text PDF:/home/krosenfe/.mozilla/firefox/5dl2iz3a.default/zotero/storage/BWS7JKKG/Cooley and Tukey - 1965 - An algorithm for the machine calculation of comple.pdf:application/pdf;Snapshot:/home/krosenfe/.mozilla/firefox/5dl2iz3a.default/zotero/storage/TRMKUDND/home.html:text/html}
}

@article{kim14a,
  title = {Implementation of a high-throughput low-latency polyphase channelizer on {GPUs}},
  volume = {2014},
  copyright = {2014 Kim and Bhattacharyya; licensee Springer.},
  issn = {1687-6180},
  url = {http://asp.eurasipjournals.com/content/2014/1/141/abstract},
  doi = {10.1186/1687-6180-2014-141},
  language = {en},
  timestamp = {2015-08-03 13:12:28},
  number = {1},
  urldate = {2015-07-15},
  journal = {{EURASIP} Journal on Advances in Signal Processing},
  author = {Kim, Scott C. and Bhattacharyya, Shuvra S.},
  month = sep,
  year = {2014},
  keywords = {DSP accelerator,GPU-based radio,GPU front-end receiver,Polyphase channelizer,polyphase filter},
  pages = {141},
  file = {Full Text PDF:/home/krosenfe/.mozilla/firefox/5dl2iz3a.default/zotero/storage/PF4A8EK4/Kim and Bhattacharyya - 2014 - Implementation of a high-throughput low-latency po.pdf:application/pdf;Snapshot:/home/krosenfe/.mozilla/firefox/5dl2iz3a.default/zotero/storage/JGM3U6JW/141.html:text/html}
}

@article{adamek14,
  title = {The Implementation of a Real-Time Polyphase Filter},
  url = {http://arxiv.org/abs/1411.3656},
  abstract = {In this article we study the suitability of dierent computational accelerators for the task of real-time data processing. The algorithm used for comparison is the polyphase filter, a standard tool in signal processing and a well established algorithm. We measure performance in FLOPs and execution time, which is a critical factor for real-time systems. For our real-time studies we have chosen a data rate of 6.5GB/s, which is the estimated data rate for a single channel on the SKAs Low Frequency Aperture Array. Our findings how that GPUs are the most likely candidate for real-time data processing. GPUs are better in both performance and power consumption.},
  timestamp = {2015-08-03 13:09:00},
  urldate = {2015-07-15},
  journal = {{arXiv}:1411.3656 {[}cs]},
  author = {Ad{\'a}mek, Karel and Novotn{\'y}, Jan and Armour, Wes},
  month = nov,
  year = {2014},
  keywords = {Computer Science - Distributed, Parallel, and Cluster Computing,Computer Science - Performance},
  annote = {Comment: Proceedings of WDS 2014, Charles University in Prague, Faculty of Mathematics and Physics Troja, Prague},
  file = {arXiv\:1411.3656 PDF:/home/krosenfe/.mozilla/firefox/5dl2iz3a.default/zotero/storage/2UTEQQMK/Ad√°mek et al. - 2014 - The Implementation of a Real-Time Polyphase Filter.pdf:application/pdf;arXiv.org Snapshot:/home/krosenfe/.mozilla/firefox/5dl2iz3a.default/zotero/storage/RHN2IWJD/1411.html:text/html},
  arxiv = {1411.3656}
}

@article{frigo_design_2005,
  title = {The Design and Implementation of {FFTW}3},
  volume = {93},
  issn = {0018-9219},
  doi = {10.1109/JPROC.2004.840301},
  abstract = {FFTW is an implementation of the discrete Fourier transform (DFT) that adapts to the hardware in order to maximize performance. This paper shows that such an approach can yield an implementation that is competitive with hand-optimized libraries, and describes the software structure that makes our current FFTW3 version flexible and adaptive. We further discuss a new algorithm for real-data DFTs of prime size, a new way of implementing DFTs by means of machine-specific single-instruction, multiple-data (SIMD) instructions, and how a special-purpose compiler can derive optimized implementations of the discrete cosine and sine transforms automatically from a DFT algorithm.},
  timestamp = {2015-07-16 12:35:47},
  number = {2},
  journal = {Proceedings of the {IEEE}},
  author = {Frigo, M. and Johnson, S.G.},
  month = feb,
  year = {2005},
  keywords = {Adaptive software,cosine transform,cosine transforms,Data structures,DFT algorithm,discrete cosine transforms,discrete Fourier transform,discrete Fourier transforms,Discrete transforms,fast Fourier transform (FFT),fast Fourier transforms,FFTW3 design,FFTW3 version,Fourier transform,Fourier transforms,hand optimized libraries,Hardware,Hartley transform,I/O tensor,machine specific single instruction,mathematics computing,Multidimensional systems,multiple data instructions,optimising compilers,Optimizing compilers,parallel programming,sine transforms,software libraries,software structure},
  pages = {216--231},
  file = {IEEE Xplore Abstract Record:/home/krosenfe/.mozilla/firefox/5dl2iz3a.default/zotero/storage/HNIT5IUQ/articleDetails.html:text/html}
}

@article{schatzman96,
  title = {Accuracy of the Discrete Fourier Transform and the Fast Fourier Transform},
  volume = {17},
  issn = {1064-8275},
  url = {http://dx.doi.org/10.1137/S1064827593247023},
  doi = {10.1137/S1064827593247023},
  abstract = {Fast Fourier transform (FFT)-based computations can be far more accurate than the  slow transforms suggest.  Discrete Fourier transforms computed through the FFT are  far more accurate than slow transforms, and convolutions  computed via FFT are far more accurate than the direct results.  However, these results depend critically on the accuracy  of the FFT software employed, which should generally be considered suspect.  Popular recursions for fast computation of the sine/cosine  table (or twiddle factors) are inaccurate due to inherent instability.  Some analyses of these recursions that have appeared heretofore  in print, suggesting stability, are incorrect.  Even in higher dimensions, the FFT is remarkably stable.},
  timestamp = {2015-08-03 13:34:24},
  number = {5},
  urldate = {2015-07-27},
  journal = {{SIAM} J. Sci. Comput.},
  author = {Schatzman, James C.},
  month = sep,
  year = {1996},
  keywords = {discrete Fourier transform (DFT),fast Fourier transform (FFT)},
  pages = {1150--1166}
}

@article{tasche_worst_2001,
  title = {Worst and Average Case Roundoff Error Analysis for {FFT}},
  volume = {41},
  issn = {0006-3835, 1572-9125},
  url = {http://link.springer.com/article/10.1023/A\%3A1021923430250},
  doi = {10.1023/A:1021923430250},
  abstract = {This paper presents both worst case and average case analysis of roundoff errors occuring in the floating point computation of fast Fourier transform (FFT) with precomputed twiddle factors and shows the strong influence of precomputation errors on the numerical stability of FFT. Numerical tests confirm the theoretical results.},
  language = {en},
  timestamp = {2015-07-27 19:01:01},
  number = {3},
  urldate = {2015-07-27},
  journal = {{BIT} Numerical Mathematics},
  author = {Tasche, Manfred and Zeuner, Hansmartin},
  month = jun,
  year = {2001},
  keywords = {average case study,Computational Mathematics and Numerical Analysis,fast Fourier transform,Mathematics, general,Numeric Computing,precomputed twiddle factors,Roundoff error analysis,worst case study},
  pages = {563--581},
  file = {Full Text PDF:/home/krosenfe/.mozilla/firefox/5dl2iz3a.default/zotero/storage/NH2QAADI/Tasche and Zeuner - 2001 - Worst and Average Case Roundoff Error Analysis for.pdf:application/pdf;Snapshot:/home/krosenfe/.mozilla/firefox/5dl2iz3a.default/zotero/storage/Z8IQWQF4/10.html:text/html}
}


